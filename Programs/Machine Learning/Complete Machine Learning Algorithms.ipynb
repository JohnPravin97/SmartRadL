{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249d6d50",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa09ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, f1_score, roc_auc_score, roc_curve, plot_roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, cross_val_predict, learning_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea5fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Overall_DA_Dataset_with_APR.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c1cd2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78712 entries, 0 to 78711\n",
      "Columns: 105 entries, x_mean to Labels\n",
      "dtypes: float64(86), int64(18), object(1)\n",
      "memory usage: 63.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c24def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asphalt_Ride        51190\n",
       "Stop                14193\n",
       "Cobblestone_Ride     9508\n",
       "Asphalt_Manhole      2824\n",
       "Asphalt_Kurb          621\n",
       "Asphalt_Bump          376\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a59bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Labels', axis=1)\n",
    "y = df[\"Labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0e9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to split the available data to train and test\n",
    "def split_train_test(df, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "\n",
    "# to normalize the columns using standard scaler\n",
    "class standardscaler(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ss=None\n",
    "        self.mean_=None\n",
    "        self.scale_=None\n",
    "    def fit(self, X, y=None):\n",
    "        self.ss=StandardScaler()\n",
    "        self.ss.fit(X)\n",
    "        self.mean_ = pd.Series(self.ss.mean_, index=X.columns)\n",
    "        self.scale_ = pd.Series(self.ss.scale_, index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        x=self.ss.transform(X)\n",
    "        numeric=pd.DataFrame(x, columns=X.columns)\n",
    "        return numeric\n",
    "\n",
    "# to normalize the columns using standard scaler\n",
    "class max_minscaler(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mms=None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.mms = MinMaxScaler()\n",
    "        self.mms.fit(X)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        x=self.mms.transform(X)\n",
    "        numeric=pd.DataFrame(x, columns=X.columns)\n",
    "        return numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d6022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d1e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 62969 entries, 60255 to 68268\n",
      "Columns: 104 entries, x_mean to Speed_(km/hr)\n",
      "dtypes: float64(86), int64(18)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357842a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mms = max_minscaler()\n",
    "pipeline = make_pipeline(mms)\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)\n",
    "'''\n",
    "\n",
    "ss = standardscaler()\n",
    "pipeline = make_pipeline(ss)\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d914f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.mean_.to_pickle(r\"C:\\Users\\arockias\\Desktop\\SmartRadL\\SmartRadL\\Programs\\Machine Learning\\Models\\ss_mean.pkl\")\n",
    "ss.scale_.to_pickle(r\"C:\\Users\\arockias\\Desktop\\SmartRadL\\SmartRadL\\Programs\\Machine Learning\\Models\\ss_scale.pkl\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5aa455",
   "metadata": {},
   "source": [
    "### Machine learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75cc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_machine_learning():\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, save_path):\n",
    "        self.X_train = X_train       \n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def logistic_regression(self, C=100, class_weight = \"balanced\", multi_class= \"ovr\"):\n",
    "        self.lr = LogisticRegression(C=C, class_weight=class_weight, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "             multi_class= multi_class, n_jobs=None, penalty='l2', random_state=None, solver='newton-cg', tol=0.0001, verbose=0, warm_start=False)\n",
    "        \n",
    "        self.lr.fit(self.X_train, self.y_train)\n",
    "        filename = self.save_path+\"\\\\\"+'lr_model.pkl'\n",
    "        joblib.dump(self.lr, open(filename, 'wb'))\n",
    "        \n",
    "        lr_train_score = self.lr.score(self.X_train, self.y_train)\n",
    "        lr_test_score = self.lr.score(self.X_test, self.y_test)\n",
    "        lr_pre = self.lr.predict(self.X_test)\n",
    "        lr_f1_s = f1_score(self.y_test, lr_pre, average =\"weighted\")\n",
    "        lr_classification_report = classification_report(self.y_test, lr_pre)\n",
    "        \n",
    "        #return lr_pre\n",
    "        return lr_train_score, lr_test_score, lr_f1_s, lr_classification_report\n",
    "     \n",
    "    def support_vector_machine(self, C=20, class_weight = \"balanced\", decision_function_shape = \"ovo\", kernel = 'rbf'):\n",
    "        self.svc = SVC(C=C, break_ties=False, cache_size=200, class_weight= class_weight, decision_function_shape= decision_function_shape,  gamma='scale', kernel= kernel,max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "        \n",
    "        self.svc.fit(self.X_train, self.y_train)\n",
    "        filename = self.save_path+\"\\\\\"+'svc_model.pkl'\n",
    "        joblib.dump(self.svc, open(filename, 'wb'))\n",
    "        \n",
    "        svc_train_score = self.svc.score(self.X_train, self.y_train)\n",
    "        svc_test_score = self.svc.score(self.X_test, self.y_test)\n",
    "        svc_pre = self.svc.predict(self.X_test)\n",
    "        svc_f1_s = f1_score(self.y_test, svc_pre, average =\"weighted\")\n",
    "        svc_classification_report = classification_report(self.y_test, svc_pre)\n",
    "        \n",
    "        #return svc_pre\n",
    "        return svc_train_score, svc_test_score, svc_f1_s, svc_classification_report\n",
    "    \n",
    "    def decision_tree(self, max_depth = 13, min_samples_leaf = 2, cri = 'gini', class_weight = \"balanced\"):\n",
    "        self.dtc = DecisionTreeClassifier(max_depth = max_depth, criterion = cri, min_samples_split=4, min_samples_leaf= min_samples_leaf, class_weight=class_weight)\n",
    "        \n",
    "        self.dtc.fit(self.X_train, self.y_train)\n",
    "        filename = self.save_path+\"\\\\\"+'dtc_model.pkl'\n",
    "        joblib.dump(self.dtc, open(filename, 'wb'))\n",
    "        \n",
    "        dtc_train_score = self.dtc.score(self.X_train, self.y_train)\n",
    "        dtc_test_score = self.dtc.score(self.X_test, self.y_test)\n",
    "        dtc_pre = self.dtc.predict(self.X_test)\n",
    "        dtc_f1_s = f1_score(self.y_test, dtc_pre, average =\"weighted\")\n",
    "        dtc_classification_report = classification_report(self.y_test, dtc_pre)\n",
    "   \n",
    "        return dtc_train_score, dtc_test_score, dtc_f1_s, self.dtc.feature_importances_,  dtc_classification_report\n",
    "\n",
    "    def XGboost(self, objective=\"multi:softprob\", random_state=42, use_label_encoder=False):\n",
    "        self.xgb = XGBClassifier(objective=objective, random_state= random_state, use_label_encoder= use_label_encoder)\n",
    "        \n",
    "        self.xgb.fit(self.X_train, y_train)\n",
    "        filename = self.save_path+\"\\\\\"+'xgb_model.pkl'\n",
    "        joblib.dump(self.xgb, open(filename, 'wb'))\n",
    "        \n",
    "        xgb_train_score = self.xgb.score(self.X_train, y_train)\n",
    "        xgb_test_score = self.xgb.score(self.X_test, y_test)\n",
    "        xgb_pre = self.xgb.predict(self.X_test)\n",
    "        xgb_f1_s = f1_score(y_test, xgb_pre, average =\"weighted\")\n",
    "   \n",
    "        return xgb_train_score, xgb_test_score, xgb_f1_s, self.xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc53bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = train_machine_learning(X_train, X_test, y_train, y_test, save_path = r\"C:\\Users\\arockias\\Desktop\\SmartRadL\\SmartRadL\\Programs\\Machine Learning\\Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37517e3f",
   "metadata": {},
   "source": [
    "##### logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba81ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arockias\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "C:\\Users\\arockias\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "C:\\Users\\arockias\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    }
   ],
   "source": [
    "lr_train_score, lr_test_score, lr_f1_score, lr_classification_report = ml.logistic_regression(C=100, class_weight = \"balanced\", multi_class= \"ovr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41766a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_score, lr_test_score, lr_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd525c2b",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_score, svc_test_score, svc_f1_score, svc_classification_report = ml.support_vector_machine(C=6, class_weight = \"balanced\", decision_function_shape = \"ovo\", kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854950e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_score, svc_test_score, svc_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab44769",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce5298",
   "metadata": {},
   "source": [
    "##### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d202f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_train_score, dtc_test_score, dtc_f1_score, dtc_importance, dtc_classification_report = ml.decision_tree(max_depth = 13, cri = 'gini', min_samples_leaf = 2, class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f06ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_train_score, dtc_test_score, dtc_f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtc_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a24081",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(dtc_importance):\n",
    "    print(X.columns[i] + ' Feature No: %i, Score: %.5f' % (i, v))\n",
    "    \n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(dtc_importance))], dtc_importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900f657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
